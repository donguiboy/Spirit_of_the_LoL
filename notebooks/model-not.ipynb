{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 18:24:13.928160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-06 18:24:14.594760: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-06 18:24:14.793933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-06 18:24:14.793956: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-06 18:24:14.916753: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-06 18:24:16.834620: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-06 18:24:16.834775: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-06 18:24:16.834781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_train = \"../data/Match_Diff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for filename in os.listdir(folder_path_train):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path_train, filename)\n",
    "        \n",
    "        # Extract the key from the filename\n",
    "        key = filename.replace(\"Match_Diff_\", \"\").replace(\".csv\", \"\")\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Delete the first column from the DataFrame\n",
    "        df = df.drop(df.columns[0], axis=1)\n",
    "        \n",
    "        # Add the DataFrame to the dictionary with the key\n",
    "        data_dict[key] = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STARTS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_json import reduce_columns_train\n",
    "\n",
    "data_dict_red={}\n",
    "\n",
    "for key, df in data_dict.items():\n",
    "    \n",
    "    data_dict_red[key] = reduce_columns_train(data_dict[key])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_preprocess import preprocess_train\n",
    "\n",
    "data_preprop = {}\n",
    "\n",
    "for key, df in data_dict_red.items():\n",
    "    \n",
    "    X = data_dict_red[key].drop(columns=\"target\")\n",
    "    \n",
    "    y = data_dict_red[key][\"target\"]\n",
    "\n",
    "    X_preprop,transformer = preprocess_train(X)\n",
    "    \n",
    "    data_preprop[key] = [X_preprop,y,transformer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['killType_KILL_ACE',\n",
       " 'killType_KILL_FIRST_BLOOD',\n",
       " 'killType_KILL_MULTI',\n",
       " 'minionsKilled',\n",
       " 'monsterType_AIR_DRAGON',\n",
       " 'monsterType_CHEMTECH_DRAGON',\n",
       " 'monsterType_EARTH_DRAGON',\n",
       " 'monsterType_FIRE_DRAGON',\n",
       " 'monsterType_HEXTECH_DRAGON',\n",
       " 'monsterType_RIFTHERALD',\n",
       " 'monsterType_WATER_DRAGON',\n",
       " 'totalGold',\n",
       " 'towerType_INNER_TURRET',\n",
       " 'towerType_OUTER_TURRET']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_of_interest = data_preprop[\"IRON\"][0].columns.tolist()\n",
    "columns_of_interest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOG MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRON\n",
      "Best Hyperparameters:  {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score:  0.7357476220185917\n",
      "PLATINUM\n",
      "Best Hyperparameters:  {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score:  0.7179814586473033\n",
      "SILVER\n",
      "Best Hyperparameters:  {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Score:  0.7126429818155621\n",
      "GOLD\n",
      "Best Hyperparameters:  {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Score:  0.7137599820730117\n",
      "BRONZE\n",
      "Best Hyperparameters:  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score:  0.7025020061905308\n",
      "CHALLENGER\n",
      "Best Hyperparameters:  {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score:  0.7233133473241978\n",
      "MASTER\n",
      "Best Hyperparameters:  {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best Score:  0.7052763483570029\n",
      "GRANDMASTER\n",
      "Best Hyperparameters:  {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best Score:  0.7123748584985016\n",
      "DIAMOND\n",
      "Best Hyperparameters:  {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Score:  0.7043819056284935\n"
     ]
    }
   ],
   "source": [
    "#Look for the best params and export the model with these\n",
    "\n",
    "fitted_models = {}\n",
    "\n",
    "for key, value in data_preprop.items():\n",
    "    print(key)\n",
    "\n",
    "    X_preprop = data_preprop[key][0]\n",
    "    y = data_preprop[key][1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_preprop, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    }\n",
    "\n",
    "    model = LogisticRegression(max_iter=5000)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "    best_model = LogisticRegression(\n",
    "        C=grid_search.best_params_['C'],\n",
    "        penalty=grid_search.best_params_['penalty'],\n",
    "        solver=grid_search.best_params_['solver'],\n",
    "        max_iter=5000\n",
    "    )\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the fitted model in the dictionary using the key as the key\n",
    "    fitted_models[key] = best_model\n",
    "\n",
    "    # Export the model as a pickle file. Uncoment if you want\n",
    "    \"\"\"\n",
    "    filename = key + '_model.pkl'\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(best_model, file)\n",
    "    print(\"Model exported as\", filename)\n",
    "    \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_folder = \"../data/predict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_json import process_folder\n",
    "from get_diff import calculate_event_differences\n",
    "from clean_preprocess import preprocess_pred\n",
    "from get_json import check_and_create_columns\n",
    "from get_json import check_and_create_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagop/code/nicolas-muzzio/Spirit_of_the_LoL/notebooks/get_diff.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_events_diff = all_events_diff.append(resta_filas, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.39876417, 0.60123583]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minute = 10\n",
    "look_events=[\"CHAMPION_SPECIAL_KILL\",\"CHAMPION_KILL\",\"ELITE_MONSTER_KILL\",\"BUILDING_KILL\"] \n",
    "folder_path = pred_folder\n",
    "\n",
    "league=\"IRON\"\n",
    "\n",
    "def prediction(pred_folder,minute,look_events,columns_of_interest,league):\n",
    "\n",
    "    df = process_folder(pred_folder,minute,look_events)\n",
    "    df_dif = calculate_event_differences(df)\n",
    "    df_dif.drop(columns=\"matchId\",inplace=True)\n",
    "    df_cc = check_and_create_columns(df_dif, columns_of_interest)\n",
    "    \n",
    "    X_pred_prep = preprocess_pred(df_cc,data_preprop[str(league)][2])\n",
    "\n",
    "    model = fitted_models[str(league)]\n",
    "    \n",
    "    results = model.predict_proba(X_pred_prep)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagop/code/nicolas-muzzio/Spirit_of_the_LoL/notebooks/get_diff.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_events_diff = all_events_diff.append(resta_filas, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.60123582850202"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(pred_folder,minute,look_events,columns_of_interest,league)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
